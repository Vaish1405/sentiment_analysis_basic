{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVmeLAhpC3WV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koyIiqMDE83L"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt_tab') # To use word_tokenize()\n",
        "nltk.download('averaged_perceptron_tagger_eng') # To use pos_tag()\n",
        "nltk.download(\"maxent_ne_chunker_tab\") # To use chunk()\n",
        "words = nltk.download(\"words\")\n",
        "nltk.download('vader_lexicon') # To use SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeOU55gRDiXW"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuGfaX_oDktL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path + '/Reviews.csv')\n",
        "\n",
        "# df.head()\n",
        "# df['Text'].values[0]\n",
        "\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPlVslnpDtur"
      },
      "outputs": [],
      "source": [
        "# Take the first 500 rows for easier calculation\n",
        "df = df[:500]\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws4_zOkHEOzd"
      },
      "source": [
        "## Quick EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA_1dOP9EL-t"
      },
      "outputs": [],
      "source": [
        "ax = df['Score'].value_counts().sort_index().plot(kind=\"bar\", title=\"Count of Reviews by starts\", figsize=(10, 5))\n",
        "\n",
        "ax.set_xlabel(\"Review Stars\")\n",
        "ax.set_ylabel(\"Number of Reviews\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbZc6nxxEuTC"
      },
      "source": [
        "## Basic NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlYYli8CEv8q"
      },
      "outputs": [],
      "source": [
        "example = df['Text'].values[10]\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZGPQ0a1Ealj"
      },
      "outputs": [],
      "source": [
        "# NLTF Function 1 -- extracting the tokens\n",
        "tokens = nltk.word_tokenize(example)\n",
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OIvC-Y6E5As"
      },
      "outputs": [],
      "source": [
        "# NLTK Function 2 -- POS Tagging\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[:10] # Link for pos_tags dictionary: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5c-c88wGBUZ"
      },
      "outputs": [],
      "source": [
        "# NLTK Function 3 -- Named Entity Recognition\n",
        "  # Groups the POS tagged information together\n",
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv_hTOx_Hnlr"
      },
      "source": [
        "# VADER Sentiment Scoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FkYN8wTHtIj"
      },
      "source": [
        "Takes the words and gives a positive, negative, or neutral statement. Depending on the word, it gives the information about how positive, or how negative the word is\n",
        "Bag of Words apporach:\n",
        "\n",
        "- Stop words are removed\n",
        "- Each word is scored and combined to get a total score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUAAVbopHnFi"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# SentimentAnalyzer object\n",
        "sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKYmdJlsG7sY"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores('I am so happy!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SItTcovtISZi"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores('This is the worst thing ever.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLxjvQLWWnTi"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvlelyfnWoqE"
      },
      "outputs": [],
      "source": [
        "# Run polarity score for entire dataset\n",
        "\n",
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "  text = row['Text']\n",
        "  myid = row[\"Id\"]\n",
        "  res[myid] = sia.polarity_scores(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRc1WODzWu8g"
      },
      "outputs": [],
      "source": [
        "vaders = pd.DataFrame(res).T #.T to make the table vertical or to flip the result\n",
        "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
        "vaders = vaders.merge(df, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUZYcIKEdCcn"
      },
      "outputs": [],
      "source": [
        "vaders.head() # this includes metadata and the sentiment score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIN3ceyXeppe"
      },
      "outputs": [],
      "source": [
        "ax = sns.barplot(data=vaders, x=\"Score\", y=\"compound\")\n",
        "ax.set_title(\"Compound Score by Amazon Star Review\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7JCRBrefVq6"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
        "\n",
        "sns.barplot(data=vaders, x=\"Score\", y=\"pos\", ax=axs[0])\n",
        "sns.barplot(data=vaders, x=\"Score\", y=\"neu\", ax=axs[1])\n",
        "sns.barplot(data=vaders, x=\"Score\", y=\"neg\", ax=axs[2])\n",
        "\n",
        "axs[0].set_title(\"Positive\")\n",
        "axs[1].set_title(\"Neutral\")\n",
        "axs[2].set_title(\"Negative\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR3Vggl4gtxr"
      },
      "source": [
        "# Roberta Pretrained Model\n",
        "\n",
        "VADER might not be sufficient since it doesn't consider the relationship between the words. Therefore, we would need to use transformer models that do this\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdVCRDjLfv0u"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsRDD7PBhBuP"
      },
      "outputs": [],
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6mqm65mhUpM"
      },
      "outputs": [],
      "source": [
        "print(example)\n",
        "sia.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S9zGVxMhm8l"
      },
      "outputs": [],
      "source": [
        "# Run for Roberta Model\n",
        "encoded_text = tokenizer(example, return_tensors='pt')\n",
        "output = model(**encoded_text)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "scores_dict = {\n",
        "    'roberta_neg' : scores[0],\n",
        "    'roberta_neu' : scores[1],\n",
        "    'roberta_pos' : scores[2]\n",
        "}\n",
        "print(scores_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oTKUI9th1pl"
      },
      "outputs": [],
      "source": [
        "def polarity_scores_roberta(example):\n",
        "  encoded_text = tokenizer(example, return_tensors='pt')\n",
        "  output = model(**encoded_text)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "  scores_dict = {\n",
        "      'roberta_neg' : scores[0],\n",
        "      'roberta_neu' : scores[1],\n",
        "      'roberta_pos' : scores[2]\n",
        "  }\n",
        "  return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN1tyQTXinG-"
      },
      "outputs": [],
      "source": [
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "  try:\n",
        "    text = row['Text']\n",
        "    myid = row['Id']\n",
        "    vader_result = sia.polarity_scores(text)\n",
        "    vader_result_rename = {}\n",
        "    for key, value in vader_result.items():\n",
        "      vader_result_rename[f\"vader_{key}\"] = value\n",
        "    roberta_result = polarity_scores_roberta(text)\n",
        "    both = {**vader_result_rename, **roberta_result}\n",
        "    res[myid] = both\n",
        "  except RuntimeError:\n",
        "    print(f'Broke for id {myid}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh9S8FTai16w"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(res).T #.T to make the table vertical or to flip the result\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
        "results_df = results_df.merge(df, how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgG4I_tb5q4S"
      },
      "source": [
        "## Compare Scores between models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjc4mgiDi4Qh"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data=results_df, vars=['vader_neg', 'vader_neu', 'vader_pos', 'roberta_neg', 'roberta_neu', 'roberta_pos'], hue='Score', palette='tab10')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K56khgn5nOy"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 1').sort_values('roberta_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG4bHy-V8ZP-"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 1').sort_values('vader_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJcgVJpL8Kug"
      },
      "outputs": [],
      "source": [
        "# negative sentiment 5 star review\n",
        "results_df.query('Score == 5').sort_values('roberta_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HO6yvt18rkl"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 5').sort_values('vader_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvR_eT2A88pm"
      },
      "source": [
        "# Transformers Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IooFfMG9AEA"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sent_pipeline = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjYER_wc8yRs"
      },
      "outputs": [],
      "source": [
        "sent_pipeline('I am so happy!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBPS1MyY9OXe"
      },
      "outputs": [],
      "source": [
        "sent_pipeline(\"I hate this so much!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvdymPF19Tuz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
